{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_alphabets = \"([A-Za-z])\"\n",
    "regex_prefixes = \"(Mr|St|Mrs|Ms|Dr|Uk)\\.\"\n",
    "regex_suffixes = \"(Inc|Ltd|Jr|Sr|Co)\"\n",
    "regex_starters = \"(Mr|Mrs|Ms|Dr|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\n",
    "# regex_acronyms = \"(?:[A-Z]\\.)+\"\n",
    "# regex_acronyms = \"(?:(?<=\\.|\\s)[A-Z]\\.)+\"\n",
    "regex_acronyms = \"([A-Z]\\.[A-Z]\\.(?:[A-Z]\\.)?)\"\n",
    "regex_sites = \"\\.(ru|com|net|org|io|gov)\"\n",
    "regex_digits = \"([0-9])\"\n",
    "regex_word = \"([A-Za-z0-9][A-Za-z0-9]*)\"\n",
    "regex_number = \"([1-9][0-9]*)\"\n",
    "regex_email = \"([A-Za-z0-9]+[.-_])*[A-Za-z0-9]+@[A-Za-z0-9-]+(\\.[A-Z|a-z]{2,})+\"\n",
    "regex_site = \"((http|https)\\:\\/\\/)?[a-zA-Z0-9\\.\\/\\?\\:@\\-_=#]+\\.([a-zA-Z]){2,6}([a-zA-Z0-9\\.\\&\\/\\?\\:@\\-_=#])*\"\n",
    "regex_year = \"([1-2][0-9][0-9][0-9])\"\n",
    "regex_month = \"(0[1-9]|1[0-2])\"\n",
    "regex_day = \"(0[1-9]|1[0-9]|2[0-9]|3[0-1])\"\n",
    "regex_hour = \"([0-1][0-9]|2[0-3])\"\n",
    "regex_min = \"([0-5][0-9])\"\n",
    "regex_sec = \"([0-5][0-9])\"\n",
    "regex_emoji = \"[\\U00010000-\\U0010ffff]\"\n",
    "regex_number_phone = \"([\\+]?[(]?[0-9]{3}[)]?[-\\s\\.]?[0-9]{3}[-\\s\\.]?[0-9]{4,6})\"\n",
    "regex_data = \"^(0?[1-9]|[12][0-9]|3[01])[\\/\\-\\.](0?[1-9]|1[012])[\\/\\-\\.]\\d{4}$\"\n",
    "regex_time = \"^([0-1]?[0-9]|2[0-3]):[0-5][0-9]$\"\n",
    "regex_index_mail_USA = \"^\\d{5}$\"\n",
    "regex_card = \"\\d{4}-?\\d{4}-?\\d{4}-?\\d{4}\"\n",
    "regex_address = \"^[a-zA-Z0-9&#192;&#193;&#194;&#195;&#196;&#197;&#198;&#199;&#200;&#201;&#202;&#203;&#204;&#205;&#206;&#207;&#208;&#209;&#210;&#211;&#212;&#213;&#214;&#216;&#217;&#218;&#219;&#220;&#221;&#223;&#224;&#225;&#226;&#227;&#228;&#229;&#230;&#231;&#232;&#233;&#234;&#235;&#236;&#237;&#238;&#239;&#241;&#242;&#243;&#244;&#245;&#246;&#248;&#249;&#250;&#251;&#252;&#253;&#255;\\.\\,\\-\\/\\']+[a-zA-Z0-9&#192;&#193;&#194;&#195;&#196;&#197;&#198;&#199;&#200;&#201;&#202;&#203;&#204;&#205;&#206;&#207;&#208;&#209;&#210;&#211;&#212;&#213;&#214;&#216;&#217;&#218;&#219;&#220;&#221;&#223;&#224;&#225;&#226;&#227;&#228;&#229;&#230;&#231;&#232;&#233;&#234;&#235;&#236;&#237;&#238;&#239;&#241;&#242;&#243;&#244;&#245;&#246;&#248;&#249;&#250;&#251;&#252;&#253;&#255;\\.\\,\\-\\/\\' ]+$\"\n",
    "regex_data_time = \"^((((31\\/(0?[13578]|1[02]))|((29|30)\\/(0?[1,3-9]|1[0-2])))\\/(1[6-9]|[2-9]\\d)?\\d{2})|(29\\/0?2\\/(((1[6-9]|[2-9]\\d)?(0[48]|[2468][048]|[13579][26])|((16|[2468][048]|[3579][26])00))))|(0?[1-9]|1\\d|2[0-8])\\/((0?[1-9])|(1[0-2]))\\/((1[6-9]|[2-9]\\d)?\\d{2})) (20|21|22|23|[0-1]?\\d):[0-5]?\\d:[0-5]?\\d$\"\n",
    "regex_states_USA = \"^((AL)|(AK)|(AS)|(AZ)|(AR)|(CA)|(CO)|(CT)|(DE)|(DC)|(FM)|(FL)|(GA)|(GU)|(HI)|(ID)|(IL)|(IN)|(IA)|(KS)|(KY)|(LA)|(ME)|(MH)|(MD)|(MA)|(MI)|(MN)|(MS)|(MO)|(MT)|(NE)|(NV)|(NH)|(NJ)|(NM)|(NY)|(NC)|(ND)|(MP)|(OH)|(OK)|(OR)|(PW)|(PA)|(PR)|(RI)|(SC)|(SD)|(TN)|(TX)|(UT)|(VT)|(VI)|(VA)|(WA)|(WV)|(WI)|(WY))$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid states card\n",
      "Valid states card\n",
      "Invalid states card\n",
      "Invalid states card\n"
     ]
    }
   ],
   "source": [
    "def isValid_regex_card(card):\n",
    "  if re.fullmatch(regex_card, card):\n",
    "    print(\"Valid states card\")\n",
    "  else:\n",
    "    print(\"Invalid states card\")\n",
    "\n",
    "isValid_regex_card(\"1234-1234-1234-1234\")\n",
    "isValid_regex_card(\"9723-4534-1343-1245\")\n",
    "isValid_regex_card(\"9723-4534-1343-124\")\n",
    "isValid_regex_card(\"9723-4534-1343-12453\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid states USA\n",
      "Valid states USA\n",
      "Invalid states USA\n",
      "Invalid states USA\n"
     ]
    }
   ],
   "source": [
    "def isValid_regex_states_USA(states_USA):\n",
    "  if re.fullmatch(regex_states_USA, states_USA):\n",
    "    print(\"Valid states USA\")\n",
    "  else:\n",
    "    print(\"Invalid states USA\")\n",
    "\n",
    "isValid_regex_states_USA(\"PA\")\n",
    "isValid_regex_states_USA(\"NJ\")\n",
    "isValid_regex_states_USA(\"Pennsylvania\")\n",
    "isValid_regex_states_USA(\"Pa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid address\n",
      "Valid address\n"
     ]
    }
   ],
   "source": [
    "def isValid_regex_address(address):\n",
    "  if re.fullmatch(regex_address, address):\n",
    "    print(\"Valid address\")\n",
    "  else:\n",
    "    print(\"Invalid address\")\n",
    "\n",
    "isValid_regex_address(\"v.le dell'industria 45/a\")\n",
    "isValid_regex_address(\"via genova 45-3-d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid index mail USA\n",
      "Valid index mail USA\n",
      "Invalid index mail USA\n",
      "Invalid index mail USA\n"
     ]
    }
   ],
   "source": [
    "def isValid_regex_index_mail_USA(index_mail_USA):\n",
    "  if re.fullmatch(regex_index_mail_USA, index_mail_USA):\n",
    "    print(\"Valid index mail USA\")\n",
    "  else:\n",
    "    print(\"Invalid index mail USA\")\n",
    "\n",
    "isValid_regex_index_mail_USA(\"55555\")\n",
    "isValid_regex_index_mail_USA(\"26727\")\n",
    "isValid_regex_index_mail_USA(\"222\")\n",
    "isValid_regex_index_mail_USA(\"2222222d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid data and time\n",
      "Invalid data and time\n",
      "Invalid data and time\n",
      "Invalid data and time\n"
     ]
    }
   ],
   "source": [
    "def isValid_regex_data_time(data_time):\n",
    "  if re.fullmatch(regex_data_time, data_time):\n",
    "    print(\"Valid data and time\")\n",
    "  else:\n",
    "    print(\"Invalid data and time\")\n",
    "\n",
    "isValid_regex_data_time(\"03.03.2002 15:33\")\n",
    "isValid_regex_data_time(\"03.03.2003 3:33:33 \")\n",
    "isValid_regex_data_time(\"31 –º–∞—Ä—Ç–∞ 2002 –≥\")\n",
    "isValid_regex_data_time(\"03.03.2002 3:33\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid time\n",
      "Valid time\n",
      "Invalid time\n",
      "Invalid time\n"
     ]
    }
   ],
   "source": [
    "def isValid_regex_time(time):\n",
    "  if re.fullmatch(regex_time, time):\n",
    "    print(\"Valid time\")\n",
    "  else:\n",
    "    print(\"Invalid time\")\n",
    "\n",
    "isValid_regex_time(\"12:02\")\n",
    "isValid_regex_time(\"08:42\")\n",
    "isValid_regex_time(\"12/02\")\n",
    "isValid_regex_time(\"24:73\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid data\n",
      "Valid data\n",
      "Valid data\n",
      "Invalid data\n",
      "Invalid data\n"
     ]
    }
   ],
   "source": [
    "def isValid_regex_data(data):\n",
    "  if re.fullmatch(regex_data, data):\n",
    "    print(\"Valid data\")\n",
    "  else:\n",
    "    print(\"Invalid data\")\n",
    "\n",
    "isValid_regex_data(\"12/02/2021\")\n",
    "isValid_regex_data(\"12-02-2021\")\n",
    "isValid_regex_data(\"12.02.2021\")\n",
    "isValid_regex_data(\"99-22-2222\")\n",
    "isValid_regex_data(\"999.22.2222\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid alphabets\n",
      "Valid alphabets\n",
      "Invalid alphabets\n",
      "Invalid alphabets\n"
     ]
    }
   ],
   "source": [
    "def isValid_regex_alphabets(alphabets):\n",
    "  if re.fullmatch(regex_alphabets, alphabets):\n",
    "    print(\"Valid alphabets\")\n",
    "  else:\n",
    "    print(\"Invalid alphabets\")\n",
    "\n",
    "isValid_regex_alphabets(\"T\")\n",
    "isValid_regex_alphabets(\"f\")\n",
    "isValid_regex_alphabets(\"–∞—ã–∞—ã\")\n",
    "isValid_regex_alphabets(\"^\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid prefix\n",
      "Valid prefix\n",
      "Invalid prefix\n",
      "Invalid prefix\n"
     ]
    }
   ],
   "source": [
    "def isValid_regex_prefixes(prefixes):\n",
    "  if re.fullmatch(regex_prefixes, prefixes):\n",
    "    print(\"Valid prefix\")\n",
    "  else:\n",
    "    print(\"Invalid prefix\")\n",
    "\n",
    "isValid_regex_prefixes(\"Mr.\")\n",
    "isValid_regex_prefixes(\"Mrs.\")\n",
    "isValid_regex_prefixes(\"sbhfbhsd6323\")\n",
    "isValid_regex_prefixes(\"&&#6bdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid suffixes\n",
      "Valid suffixes\n",
      "Invalid suffixes\n",
      "Invalid suffixes\n"
     ]
    }
   ],
   "source": [
    "def isValid_regex_suffixes(suffixes):\n",
    "  if re.fullmatch(regex_suffixes, suffixes):\n",
    "    print(\"Valid suffixes\")\n",
    "  else:\n",
    "    print(\"Invalid suffixes\")\n",
    "\n",
    "isValid_regex_suffixes(\"Inc\")\n",
    "isValid_regex_suffixes(\"Co\")\n",
    "isValid_regex_suffixes(\"Test\")\n",
    "isValid_regex_suffixes(\"44\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid acronyms\n",
      "Valid acronyms\n",
      "Invalid acronyms\n",
      "Invalid acronyms\n"
     ]
    }
   ],
   "source": [
    "def isValid_regex_acronyms(acronyms):\n",
    "  if re.fullmatch(regex_acronyms, acronyms):\n",
    "    print(\"Valid acronyms\")\n",
    "  else:\n",
    "    print(\"Invalid acronyms\")\n",
    "\n",
    "isValid_regex_acronyms(\"U.S.A.\")\n",
    "isValid_regex_acronyms(\"B.B.C.\")\n",
    "isValid_regex_acronyms(\"B.Bc\")\n",
    "isValid_regex_acronyms(\"B.B.C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid sites\n",
      "Valid sites\n",
      "Invalid sites\n",
      "Invalid sites\n"
     ]
    }
   ],
   "source": [
    "def isValid_regex_sites(sites):\n",
    "  if re.fullmatch(regex_sites, sites):\n",
    "    print(\"Valid sites\")\n",
    "  else:\n",
    "    print(\"Invalid sites\")\n",
    "\n",
    "isValid_regex_sites(\".com\")\n",
    "isValid_regex_sites(\".ru\")\n",
    "isValid_regex_sites(\".f3m\")\n",
    "isValid_regex_sites(\".test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid digits\n",
      "Valid digits\n",
      "Invalid digits\n",
      "Invalid digits\n"
     ]
    }
   ],
   "source": [
    "def isValid_regex_digits(digits):\n",
    "  if re.fullmatch(regex_digits, digits):\n",
    "    print(\"Valid digits\")\n",
    "  else:\n",
    "    print(\"Invalid digits\")\n",
    "\n",
    "isValid_regex_digits(\"0\")\n",
    "isValid_regex_digits(\"2\")\n",
    "isValid_regex_digits(\"_hbdsfh4\")\n",
    "isValid_regex_digits(\"-3434\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid word\n",
      "Valid word\n",
      "Invalid word\n",
      "Invalid word\n"
     ]
    }
   ],
   "source": [
    "def isValid_regex_word(word):\n",
    "  if re.fullmatch(regex_word, word):\n",
    "    print(\"Valid word\")\n",
    "  else:\n",
    "    print(\"Invalid word\")\n",
    "\n",
    "isValid_regex_word(\"01test\")\n",
    "isValid_regex_word(\"lol\")\n",
    "isValid_regex_word(\"24324 wfs\")\n",
    "isValid_regex_word(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid site\n",
      "Valid site\n",
      "Invalid site\n",
      "Invalid site\n"
     ]
    }
   ],
   "source": [
    "def isValid_regex_site(site):\n",
    "  if re.fullmatch(regex_site, site):\n",
    "    print(\"Valid site\")\n",
    "  else:\n",
    "    print(\"Invalid site\")\n",
    "\n",
    "isValid_regex_site(\"http://stackoverflow.com/questions/6427530/regular-expression-pattern-to-match-url-withwww/Christina.V.Scott@gmail.com\")\n",
    "isValid_regex_site(\"https://test.test-75.1474.stackoverflow.com/\")\n",
    "isValid_regex_site(\"http://test.comdf35667`~.com\")\n",
    "isValid_regex_site(\"https://test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid email\n",
      "Valid email\n",
      "Invalid email\n",
      "Invalid email\n"
     ]
    }
   ],
   "source": [
    "def isValid_regex_email(email):\n",
    "    if re.fullmatch(regex_email, email):\n",
    "      print(\"Valid email\")\n",
    "    else:\n",
    "      print(\"Invalid email\")\n",
    "\n",
    "isValid_regex_email(\"name.surname@gmail.com\")\n",
    "isValid_regex_email(\"anonymous123@yahoo.co.ru\")\n",
    "isValid_regex_email(\"anonymous123@...ru\")\n",
    "isValid_regex_email(\"...@domain.ru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid year\n",
      "Valid year\n",
      "Invalid year\n",
      "Invalid year\n"
     ]
    }
   ],
   "source": [
    "def isValid_regex_year(year):\n",
    "    if re.fullmatch(regex_year, year):\n",
    "      print(\"Valid year\")\n",
    "    else:\n",
    "      print(\"Invalid year\")\n",
    "\n",
    "isValid_regex_year(\"2020\")\n",
    "isValid_regex_year(\"2014\")\n",
    "isValid_regex_year(\"0999\")\n",
    "isValid_regex_year(\"20302\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid month\n",
      "Valid month\n",
      "Invalid month\n",
      "Invalid month\n"
     ]
    }
   ],
   "source": [
    "def isValid_regex_month(month):\n",
    "    if re.fullmatch(regex_month, month):\n",
    "      print(\"Valid month\")\n",
    "    else:\n",
    "      print(\"Invalid month\")\n",
    "\n",
    "isValid_regex_month(\"01\")\n",
    "isValid_regex_month(\"12\")\n",
    "isValid_regex_month(\"16\")\n",
    "isValid_regex_month(\"222\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid day\n",
      "Valid day\n",
      "Invalid day\n",
      "Invalid day\n"
     ]
    }
   ],
   "source": [
    "def isValid_regex_day(day):\n",
    "    if re.fullmatch(regex_day, day):\n",
    "      print(\"Valid day\")\n",
    "    else:\n",
    "      print(\"Invalid day\")\n",
    "\n",
    "isValid_regex_day(\"01\")\n",
    "isValid_regex_day(\"12\")\n",
    "isValid_regex_day(\"32\")\n",
    "isValid_regex_day(\"222\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid hour\n",
      "Invalid hour\n",
      "Invalid hour\n",
      "Invalid hour\n"
     ]
    }
   ],
   "source": [
    "def isValid_regex_hour(hour):\n",
    "    if re.fullmatch(regex_hour, hour):\n",
    "      print(\"Valid hour\")\n",
    "    else:\n",
    "      print(\"Invalid hour\")\n",
    "\n",
    "isValid_regex_hour(\"12\")\n",
    "isValid_regex_hour(\"24\")\n",
    "isValid_regex_hour(\"32\")\n",
    "isValid_regex_hour(\"222\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid min\n",
      "Valid min\n",
      "Invalid min\n",
      "Invalid min\n"
     ]
    }
   ],
   "source": [
    "def isValid_regex_min(min):\n",
    "    if re.fullmatch(regex_min, min):\n",
    "      print(\"Valid min\")\n",
    "    else:\n",
    "      print(\"Invalid min\")\n",
    "\n",
    "isValid_regex_min(\"12\")\n",
    "isValid_regex_min(\"59\")\n",
    "isValid_regex_min(\"324\")\n",
    "isValid_regex_min(\"222\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid sec\n",
      "Valid sec\n",
      "Invalid sec\n",
      "Invalid sec\n"
     ]
    }
   ],
   "source": [
    "def isValid_regex_sec(sec):\n",
    "    if re.fullmatch(regex_sec, sec):\n",
    "      print(\"Valid sec\")\n",
    "    else:\n",
    "      print(\"Invalid sec\")\n",
    "\n",
    "isValid_regex_sec(\"12\")\n",
    "isValid_regex_sec(\"59\")\n",
    "isValid_regex_sec(\"324\")\n",
    "isValid_regex_sec(\"222\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid emoji\n",
      "Valid emoji\n",
      "Valid emoji\n",
      "Invalid emoji\n",
      "Invalid emoji\n"
     ]
    }
   ],
   "source": [
    "def isValid_regex_emoji(emoji):\n",
    "    if re.fullmatch(\"[\\U00010000-\\U0010ffff]\", emoji):\n",
    "      print(\"Valid emoji\")\n",
    "    else:\n",
    "      print(\"Invalid emoji\")\n",
    "\n",
    "isValid_regex_emoji(\"üôÑ\")\n",
    "isValid_regex_emoji(\"ü§î\")\n",
    "isValid_regex_emoji(\"üôÖ\")\n",
    "isValid_regex_emoji(\"222\")\n",
    "isValid_regex_emoji(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid number\n",
      "Valid number\n",
      "Invalid number\n",
      "Invalid number\n"
     ]
    }
   ],
   "source": [
    "def isValid_regex_number_phone(number):\n",
    "    if re.fullmatch(regex_number_phone, number):\n",
    "      print(\"Valid number\")\n",
    "    else:\n",
    "      print(\"Invalid number\")\n",
    "\n",
    "isValid_regex_number_phone(\"+919367788755\")\n",
    "isValid_regex_number_phone(\"8989829304\")\n",
    "isValid_regex_number_phone(\"123765\")\n",
    "isValid_regex_number_phone(\"1-1-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_sentences(text):\n",
    "    text = \" \" + text + \"  \"\n",
    "    text = re.sub(\"\\s\" + regex_alphabets + \"\\. \", \" \\\\1<dot> \", text)\n",
    "    text = re.sub(regex_acronyms + \" \" + regex_starters, \"\\\\1<stop> \\\\2\", text)\n",
    "    text = re.sub(regex_alphabets + \"\\.\" + regex_alphabets + \"\\.\" + regex_alphabets + \"\\.\", \"\\\\1<dot>\\\\2<dot>\\\\3<dot>\", text)\n",
    "    text = re.sub(regex_alphabets + \"\\.\" + regex_alphabets + \"\\.\", \"\\\\1<dot>\\\\2<dot>\", text)\n",
    "    text = re.sub(\" \" + regex_suffixes + \"\\. \" + regex_starters, \" \\\\1<stop> \\\\2\", text)\n",
    "    text = re.sub(\" \" + regex_suffixes + \"\\.\", \" \\\\1<dot>\", text)\n",
    "    text = re.sub(\" \" + regex_alphabets + \"\\.\", \" \\\\1<dot>\", text)\n",
    "    text = re.sub(regex_word + \"\\.\" + regex_word + \"\\.\" + regex_word + \"\\.\" + regex_word + \"@\" + regex_word + \"\\.\" + regex_word + \"\\.\" + regex_word, \"<\\\\1<dot>\\\\2<dot>\\\\3<dot>\\\\4@\\\\5<dot>\\\\6<dot>\\\\7>\", text)\n",
    "    text = re.sub(regex_word + \"\\.\" + regex_word + \"@\" + regex_word + \"\\.\" + regex_word + \"\\.\" + regex_word + \"\\.\" + regex_word, \"<\\\\1<dot>\\\\2@\\\\3<dot>\\\\4<dot>\\\\5<dot>\\\\6\", text)\n",
    "    text = re.sub(regex_word + \"\\.\" + regex_word + \"@\" + regex_word + \"\\.\" + regex_word + \"\\.\" + regex_word, \"<\\\\1<dot>\\\\2@\\\\3<dot>\\\\4<dot>\\\\5>\", text)\n",
    "    text = re.sub(\"<\" + regex_word + \"\\.\" + regex_word + \"\\.\" + regex_word + \"@\" + regex_word + \"\\.\" + regex_word + \"\\.\" + regex_word + \">\", \"<\\\\1<dot>\\\\2<dot>\\\\3@\\\\4<dot>\\\\5<dot>\\\\6>\", text)\n",
    "    text = re.sub(regex_number + \"-\" + regex_number, \"\\\\1-\\\\2\", text)\n",
    "    text = re.sub(regex_number + \"\\.\" + regex_number, \"\\\\1<dot>\\\\2\", text)\n",
    "    text = re.sub(regex_prefixes, \"\\\\1<dot>\", text)\n",
    "    text = re.sub(regex_sites, \"<dot>\\\\1\", text)\n",
    "    text = re.sub(regex_digits + \"\\.\" + regex_digits, \"\\\\1<dot>\\\\2\", text)\n",
    "    text = re.sub(\"<\" + regex_word + \"@\" + regex_word + \"\\.\" + regex_word + \"\\.\" + regex_word + \">\", \"<\\\\1@\\\\2<dot>\\\\3<dot>\\\\4>\", text)\n",
    "    text = re.sub(regex_word + \"@\" + regex_word + \"\\.\" + regex_word + \"\\.\" + regex_word, \"\\\\1@\\\\2<dot>\\\\3<dot>\\\\4\", text)\n",
    "    text = re.sub(regex_year + regex_month + regex_day, \"\\\\1\\\\2\\\\3\", text)\n",
    "    text = re.sub(regex_hour + regex_min + regex_sec, \"\\\\1\\\\2\\\\3\", text)\n",
    "    text = re.sub(regex_year + regex_month + regex_day + regex_hour + regex_min + regex_sec, \"\\\\1\\\\2\\\\3\\\\4\\\\5\\\\6\", text)\n",
    "    if \"...\" in text: text = text.replace(\"...\", \"<dot><dot><dot>\")\n",
    "    if \"!!!\" in text: text = text.replace(\"!!!\", \"<exclamation><exclamation><exclamation>\")\n",
    "    if \"!!!\" in text: text = text.replace(\"???\", \"<question><question><question>\")\n",
    "    if \"Ph.D\" in text: text = text.replace(\"Ph.D.\", \"Ph<dot>D<dot>\")\n",
    "    if \"‚Äù\" in text: text = text.replace(\".‚Äù\", \"‚Äù.\")\n",
    "    if \"\\\"\" in text: text = text.replace(\".\\\"\", \"\\\".\")\n",
    "    if \"!\" in text: text = text.replace(\"!\\\"\", \"\\\"!\")\n",
    "    if \"?\" in text: text = text.replace(\"?\\\"\", \"\\\"?\")\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    text = text.replace(\".\", \".<stop>\")\n",
    "    text = text.replace(\"?\", \"?<stop>\")\n",
    "    text = text.replace(\"!\", \"!<stop>\")\n",
    "    text = text.replace(\"<dot>\", \".\")\n",
    "    text = text.replace(\"<exclamation>\", \"!\")\n",
    "    text = text.replace(\"<question>\", \"?\")\n",
    "    sentences = text.split(\"<stop>\")\n",
    "    sentences = sentences[:-1]\n",
    "    sentences = [s.strip() for s in sentences]\n",
    "\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['From: mathew <mathew@mantis.co.uk> Subject: Re: university violating separation of church/state?',\n",
       " 'Organization: Mantis Consultants, Cambridge.',\n",
       " 'UK.',\n",
       " 'X-Newsreader: rusnews v1.01 Lines: 29  dmn@kepler.unh.edu (...until kings become philosophers or philosophers become kings) writes: >      Recently, RAs have been ordered (and none have resisted or cared about > it apparently) to post a religious flyer entitled _The Soul Scroll: Thoughts > on religion, spirituality, and matters of the soul_ on the inside of bathroom > stall doors.',\n",
       " '(at my school, the University of New Hampshire) It is some sort > of newsletter assembled by a Hall Director somewhere on campus.',\n",
       " \"It poses a > question about 'spirituality' each issue, and solicits responses to be  > included in the next 'issue.\",\n",
       " \"' It's all pretty vague.\",\n",
       " \"I assume it's put out > by a Christian, but they're very careful not to mention Jesus or the bible.\",\n",
       " '> I\\'ve heard someone defend it, saying \"Well it doesn\\'t support any one religion.',\n",
       " '> \" So what?',\n",
       " '?',\n",
       " '?',\n",
       " 'This is a STATE university, and as a strong supporter of the > separation of church and state, I was enraged.',\n",
       " '>  >      What can I do about this?',\n",
       " \"It sounds to me like it's just SCREAMING OUT for parody.\",\n",
       " \"Give a copy to your friendly neighbourhood SubGenius preacher; with luck, he'll run it through the mental mincer and hand you back an outrageously offensive and gut-bustingly funny parody you can paste over the originals.\"]"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_file = \"20news-bydate-train/alt.atheism/\"\n",
    "files = os.listdir(path_file)\n",
    "file = 3\n",
    "print(files[file])\n",
    "letter = open(path_file + files[file], \"r\").read()\n",
    "split_into_sentences(letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from pprint import pprint\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\dimap\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\dimap\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc82874ff4a342e2b57c189e7c4c417b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='i', max=10), Output()), _dom_classes=('widget-interact',‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "language = \"english\"\n",
    "split_text = \"\\n\\n\"\n",
    "path_file = \"20news-bydate-train/rec.autos/\"\n",
    "files = os.listdir(path_file)\n",
    "file = 2\n",
    "print(files[file])\n",
    "letter = open(path_file + files[file], \"r\").read()\n",
    "\n",
    "def split_letter(text):\n",
    "    head_body = text.split(split_text)\n",
    "    return head_body[0], split_text.join(head_body[1:]) \n",
    "\n",
    "head, body = split_letter(letter)\n",
    "\n",
    "items = split_into_sentences(body)\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "stemmer = SnowballStemmer(language)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "items\n",
    "\n",
    "def tokenize(sentence):\n",
    "    sentence = re.sub(\"I've\", \"I<split>have\", sentence)\n",
    "    sentence = re.sub(\"i've\", \"i<split>have\", sentence)\n",
    "    sentence = re.sub(\"I'as\", \"i<split>has\", sentence)\n",
    "    sentence = re.sub(\"i'as\", \"i<split>has\", sentence)\n",
    "    sentence = re.sub(\"I'm\", \"I<split>am\", sentence)\n",
    "    sentence = re.sub(\"i'm\", \"i<split>am\", sentence)\n",
    "    sentence = re.sub(\"He's\", \"He<split>is\", sentence)\n",
    "    sentence = re.sub(\"he's\", \"he<split>is\", sentence)\n",
    "    sentence = re.sub(\"She's\", \"She<split>is\", sentence)\n",
    "    sentence = re.sub(\"she's\", \"she<split>is\", sentence)\n",
    "    sentence = re.sub(\"It's\", \"It<split>is\", sentence)\n",
    "    sentence = re.sub(\"it's\", \"it<split>is\", sentence)\n",
    "    sentence = re.sub(\"We're\", \"We<split>are\", sentence)\n",
    "    sentence = re.sub(\"we'are\", \"we<split>are\", sentence)\n",
    "    sentence = re.sub(\"They're\", \"They<split>are\", sentence)\n",
    "    sentence = re.sub(\"they'are\", \"they<split>are\", sentence)\n",
    "    sentence = re.sub(\"Can't\", \"Can<split>not\", sentence)\n",
    "    sentence = re.sub(\"can't\", \"can<split>not\", sentence)\n",
    "    sentence = re.sub(\"Aren't\", \"Are<split>not\", sentence)\n",
    "    sentence = re.sub(\"aren't\", \"are<split>not\", sentence)\n",
    "    sentence = re.sub(\"He's\", \"He<split>is\", sentence)\n",
    "    sentence = re.sub(\"he's\", \"he<split>is\", sentence)\n",
    "    sentence = re.sub(\"I'd\", \"I<split>had\", sentence)\n",
    "    sentence = re.sub(\"i'd\", \"i<split>had\", sentence)\n",
    "    sentence = re.sub(\"I'll\", \"I<split>will\", sentence)\n",
    "    sentence = re.sub(\"i'll\", \"i<split>will\", sentence)\n",
    "    sentence = re.sub(\"She'll\", \"She<split>will\", sentence)\n",
    "    sentence = re.sub(\"she'll\", \"she<split>will\", sentence)\n",
    "    sentence = re.sub(\"He'll\", \"he<split>will\", sentence)\n",
    "    sentence = re.sub(\"he'll\", \"he<split>will\", sentence)\n",
    "    sentence = re.sub(\"You'll\", \"You<split>will\", sentence)\n",
    "    sentence = re.sub(\"you'll\", \"you<split>will\", sentence)\n",
    "    sentence = re.sub(\"Isn't\", \"Is<split>not\", sentence)\n",
    "    sentence = re.sub(\"isn't\", \"is<split>not\", sentence)\n",
    "    sentence = re.sub(\" \" + regex_number + \"s\", \"\\\\1<split>seconds\", sentence)\n",
    "    sentence = re.sub(\">\" + regex_word, \"><split>\\\\1\", sentence)\n",
    "    sentence = re.sub(\"\\\\\" + \"(\" + regex_word, \"(<split>\\\\1\", sentence)\n",
    "    sentence = re.sub(regex_word + \"\\\\\" + \")\", \"\\\\1<split>)\", sentence)\n",
    "    sentence = re.sub(regex_number + \",\" + regex_number, \"\\\\1<coma>\\\\2\", sentence)\n",
    "    sentence = re.sub(regex_number + \",\" + regex_number + \",\" + regex_number, \"\\\\1<coma>\\\\2<coma>\\\\3\", sentence)\n",
    "    sentence = re.sub(regex_number + \"'\" + regex_number + \",\" + regex_number, \"\\\\1'\\\\2<coma>\\\\3\", sentence)\n",
    "    sentence = re.sub(regex_number + \"\\.\" + regex_number, \"\\\\1<dot>\\\\2\", sentence)\n",
    "    sentence = re.sub(regex_number + \"\\.\" + regex_number + \"\\.\" + regex_number, \"\\\\1<dot>\\\\2<dot>\\\\3\", sentence)\n",
    "    sentence = re.sub(regex_word + \"\\.\" + regex_word + \"\\.\" + regex_word + \"@\" + regex_word + \"\\.\" + regex_word + \"\\.\" + regex_word, \"<split>\\\\1<dot>\\\\2<dot>\\\\3@\\\\4<dot>\\\\5<dot>\\\\6<split>\", sentence)\n",
    "    sentence = re.sub(\"<\" + regex_word + \"\\.\" + regex_word + \"@\" + regex_word + \"\\.\" + regex_word + \"\\.\" + regex_word + \">\", \"<split>\\\\1<dot>\\\\2@\\\\3<dot>\\\\4<dot>\\\\5<split>\", sentence)\n",
    "    sentence = re.sub(regex_word + \"@\" + regex_word + \"\\.\" + regex_word + \"\\.\" + regex_word, \"\\\\1@\\\\2<dot>\\\\3<dot>\\\\4\", sentence)\n",
    "    sentence = re.sub(\"<\" + regex_word + \"\\.\" + regex_word + \"@\" + regex_word + \"\\.\" + regex_word + \"\\.\" + regex_word + \">\", \"<split>\\\\1.\\\\2@\\\\3.\\\\4.\\\\5<split>\", sentence)\n",
    "    sentence = re.sub(regex_word + \",\" + regex_word, \"<split>\\\\1<coma>\\\\2<split>\", sentence)\n",
    "    sentence = re.sub(\"<\" + regex_word + \"\\.\" + regex_word + \"\\.\" + regex_word + \"@\" + regex_word + \"\\.\" + regex_word + \">\", \"<\\\\1<dot>\\\\2<dot>\\\\3@\\\\4<dot>\\\\5>\", sentence)\n",
    "    sentence = re.sub(regex_word + \"\\.\" + \"\\.\" + \"\\.\" + regex_word, \"<split>\\\\1<split><dot><dot><dot><split>\\\\2<split><dot><split>\", sentence)\n",
    "    sentence = re.sub(regex_time, \"\\\\1\", sentence)\n",
    "    sentence = re.sub(regex_data_time, \"<split>\\\\1<split>\", sentence)\n",
    "    sentence = re.sub(regex_states_USA, \"<split>\\\\1<split>\", sentence)\n",
    "    for r in \" .\":\n",
    "        sentence = sentence.replace(r, '<split>')\n",
    "    for r in [\",\",\":\",\";\",\"?\",\"!\", '\"', \"'\", \"/\", \"*\"]:\n",
    "        sentence = re.sub(\"\\\\\" + r + regex_word, f\"{r}<split>\\\\1\", sentence)\n",
    "        sentence = re.sub(regex_word + \"\\\\\" + r, f\"\\\\1<split>{r}\", sentence)\n",
    "    sentence = sentence.replace(\"<dot>\", \".\")\n",
    "    sentence = sentence.replace(\"<coma>\", \",\")\n",
    "\n",
    "    tokens = sentence.split('<split>')\n",
    "    return [(x, stemmer.stem(x), lemmatizer.lemmatize(x)) for x in tokens if x]\n",
    "\n",
    "maxI = 10\n",
    "\n",
    "@interact\n",
    "def test(i=widgets.IntSlider(min=0, max=maxI, step=1, value=0)):\n",
    "    sentence = split_into_sentences(body)[i]\n",
    "    pprint(sentence)\n",
    "    pprint(tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism\n",
      "comp.graphics\n",
      "comp.os.ms-windows.misc\n",
      "comp.sys.ibm.pc.hardware\n",
      "comp.sys.mac.hardware\n",
      "comp.windows.x\n",
      "misc.forsale\n",
      "rec.autos\n",
      "rec.motorcycles\n",
      "rec.sport.baseball\n",
      "rec.sport.hockey\n",
      "sci.crypt\n",
      "sci.electronics\n",
      "sci.med\n",
      "sci.space\n",
      "soc.religion.christian\n",
      "talk.politics.guns\n",
      "talk.politics.mideast\n",
      "talk.politics.misc\n",
      "talk.religion.misc\n"
     ]
    }
   ],
   "source": [
    "path_folder = \"20news-bydate-train/\"\n",
    "folders = os.listdir(path_folder)\n",
    "\n",
    "\n",
    "for folder in folders:\n",
    "    files = os.listdir(f\"{path_folder}/{folder}/\")\n",
    "    print(folder)\n",
    "    \n",
    "    for file in files:\n",
    "        os.makedirs(f\"out/{folder}/{file}.tsv\", exist_ok=True)\n",
    "        out = open(f\"out/{folder}.{file}.tsv\", \"w\")\n",
    "        letter = open(f\"{path_folder}/{folder}/{file}\", \"r\").read()\n",
    "        head, body = split_letter(letter)\n",
    "\n",
    "        for sentence in split_into_sentences(head):\n",
    "            for token, stem, lem in tokenize(sentence):\n",
    "                out.write(f\"{token}\\t{stem}\\t{lem}\\n\")\n",
    "            out.write(\"\\n\")\n",
    "\n",
    "        for sentence in split_into_sentences(body):\n",
    "            for token, stem, lem in tokenize(sentence):\n",
    "                out.write(f\"{token}\\t{stem}\\t{lem}\\n\")\n",
    "            out.write(\"\\n\")\n",
    "\n",
    "        out.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dcaa3af6a1af33b1dcd03c1f1d8b554272fc3aaf7088c1c573418c1888511ca1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
