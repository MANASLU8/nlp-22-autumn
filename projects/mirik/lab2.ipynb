{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from pprint import pprint\n",
    "import os\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "stemmer = SnowballStemmer(language=\"english\")\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "import re\n",
    "alphabets= \"([A-Za-z])\"\n",
    "prefixes = \"(Mr|St|Mrs|Ms|Dr)[.]\"\n",
    "suffixes = \"(Inc|Ltd|Jr|Sr|Co)\"\n",
    "starters = \"(Mr|Mrs|Ms|Dr|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\n",
    "acronyms = \"([A-Z][.][A-Z][.](?:[A-Z][.])?)\"\n",
    "websites = \"[.](com|net|org|io|gov|me|edu|ru|ua)\"\n",
    "digits = \"([0-9])\"\n",
    "word = \"([A-Za-z0-9][A-Za-z0-9]*)\"\n",
    "number = \"([1-9][0-9]*)\"\n",
    "\n",
    "def split_into_sentences(text):\n",
    "    text = \" \" + text + \"  \"\n",
    "    text = text.replace(\"\\n>>>>\",\" \")\n",
    "    text = text.replace(\"\\n>>>\",\" \")\n",
    "    text = text.replace(\"\\n>>\",\" \")\n",
    "    text = text.replace(\"\\n>\",\" \")\n",
    "    text = text.replace(\"\\n\",\" \")\n",
    "    text = re.sub(f\"<{word}[.]{word}[.]{word}[.]{word}@{word}[.]{word}[.]{word}>\", \"<\\\\1<prd>\\\\2<prd>\\\\3<prd>\\\\4@\\\\5<prd>\\\\6<prd>\\\\7>\", text)\n",
    "    text = re.sub(f\"<{word}[.]{word}@{word}[.]{word}[.]{word}>\", \"<\\\\1<prd>\\\\2@\\\\3<prd>\\\\4<prd>\\\\5>\", text)\n",
    "    text = re.sub(f\"{word}@{word}[.]{word}[.]{word}\", \"\\\\1@\\\\2<prd>\\\\3<prd>\\\\4\", text)\n",
    "    text = re.sub(prefixes,\"\\\\1<prd>\",text)\n",
    "    text = re.sub(websites,\"<prd>\\\\1\",text)\n",
    "    text = re.sub(digits + \"[.]\" + digits,\"\\\\1<prd>\\\\2\",text)\n",
    "    if \"...\" in text: text = text.replace(\"...\",\"<prd><prd><prd>\")\n",
    "    if \"Ph.D\" in text: text = text.replace(\"Ph.D.\",\"Ph<prd>D<prd>\")\n",
    "    text = re.sub(\"\\s\" + alphabets + \"[.] \",\" \\\\1<prd> \",text)\n",
    "    text = re.sub(acronyms+\" \"+starters,\"\\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\\\\3<prd>\",text)\n",
    "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.] \"+starters,\" \\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.]\",\" \\\\1<prd>\",text)\n",
    "    text = re.sub(\" \" + alphabets + \"[.]\",\" \\\\1<prd>\",text)\n",
    "    if \"”\" in text: text = text.replace(\".”\",\"”.\")\n",
    "    if \"\\\"\" in text: text = text.replace(\".\\\"\",\"\\\".\")\n",
    "    if \"!\" in text: text = text.replace(\"!\\\"\",\"\\\"!\")\n",
    "    if \"?\" in text: text = text.replace(\"?\\\"\",\"\\\"?\")\n",
    "    text = text.replace(\".\",\".<stop>\")\n",
    "    text = text.replace(\"?\",\"?<stop>\")\n",
    "    text = text.replace(\"!\",\"!<stop>\")\n",
    "    text = text.replace(\"<prd>\",\".\")\n",
    "    sentences = text.split(\"<stop>\")\n",
    "    sentences = sentences[:-1]\n",
    "    sentences = [s.strip() for s in sentences]\n",
    "    return sentences\n",
    "\n",
    "def split_mail(text):\n",
    "    head_body = text.split(\"\\n\\n\")\n",
    "    return head_body[0], \"\\n\\n\".join(head_body[1:]) \n",
    "\n",
    "from re import S\n",
    "\n",
    "files = os.listdir(\"20news-bydate-train/alt.atheism/\")\n",
    "file = 0\n",
    "print(files[file])\n",
    "mail = open(\"20news-bydate-train/alt.atheism/\" + files[file], \"r\").read()\n",
    "head, body = split_mail(mail)\n",
    "\n",
    "def tokenize(sentence):\n",
    "    #TODO: Можно еще смайлики добавить но мне влом их все перегонять в словарь\n",
    "    #TODO: Можно еще добавить время 22:11\n",
    "    sentence = re.sub(f\">{word}\", \"><split>\\\\1\", sentence)\n",
    "\n",
    "    sentence = re.sub(f\"\\\\({word}\", \"(<split>\\\\1\", sentence)\n",
    "    sentence = re.sub(f\"{word}\\\\)\", \"\\\\1<split>)\", sentence)\n",
    "    sentence = re.sub(f\"I'm\", \"I<split>am\", sentence)\n",
    "\n",
    "    sentence = re.sub(f\"${word}'d\", \"\\\\1<split>woud\", sentence)\n",
    "    sentence = re.sub(f\"{number},{number}\", \"\\\\1<coma>\\\\2\", sentence)\n",
    "\n",
    "    sentence = re.sub(f\"{number},{number},{number}\", \"\\\\1<coma>\\\\2<coma>\\\\3\", sentence)\n",
    "\n",
    "    sentence = re.sub(f\"{number}'{number},{number}\", \"\\\\1'\\\\2<coma>\\\\3\", sentence)\n",
    "\n",
    "    sentence = re.sub(f\"{number}[.]{number}\", \"\\\\1<dot>\\\\2\", sentence)\n",
    "    sentence = re.sub(f\"{number}[.]{number}.{number}\", \"\\\\1<dot>\\\\2<dot>\\\\3\", sentence)\n",
    "\n",
    "    sentence = re.sub(f\"{word}[.]{word}[.]{word}@{word}[.]{word}[.]{word}\", \"<split>\\\\1<dot>\\\\2<dot>\\\\3@\\\\4<dot>\\\\5<dot>\\\\6<split>\", sentence)\n",
    "    sentence = re.sub(f\"<{word}[.]{word}@{word}[.]{word}[.]{word}>\", \"<split>\\\\1<dot>\\\\2@\\\\3<dot>\\\\4<dot>\\\\5<split>\", sentence)\n",
    "    sentence = re.sub(f\"{word}@{word}[.]{word}[.]{word}\", \"\\\\1@\\\\2<dot>\\\\3<dot>\\\\4<split>\", sentence)\n",
    "\n",
    "    sentence = re.sub(f\"<{word}@{word}[.]{word}>\", \"<<split>\\\\1@\\\\2<dot>\\\\3<split>><split>\", sentence)\n",
    "    sentence = re.sub(f\"{word}@{word}[.]{word}\", \"\\\\1@\\\\2<dot>\\\\3<split>\", sentence)\n",
    "\n",
    "    sentence = re.sub(f\"<{word}[.]{word}@{word}[.]{word}[.]{word}>\", \"<split>\\\\1<dot>\\\\2@\\\\3<dot>\\\\4<dot>\\\\5<split>\", sentence)\n",
    "\n",
    "    sentence = sentence.replace(\"...\", '<dot><dot><dot>')\n",
    "    for r in \" \":\n",
    "        sentence = sentence.replace(r, '<split>')\n",
    "    for r in [\".\", \",\",\":\",\";\",\"?\",\"!\", '\"', \"'\", \"/\", \"*\", \"$\"]:\n",
    "        sentence = re.sub(f\"\\\\{r}{word}\", f\"{r}<split>\\\\1\", sentence)\n",
    "        sentence = re.sub(f\"{word}\\\\{r}\", f\"\\\\1<split>{r}\", sentence)\n",
    "\n",
    "    sentence = sentence.replace(\"<dot>\", \".\")\n",
    "\n",
    "    sentence = sentence.replace(\"<coma>\", \",\")\n",
    "\n",
    "    tokens = sentence.split('<split>')\n",
    "    return [(x, stemmer.stem(x), lemmatizer.lemmatize(stemmer.stem(x))) for x in tokens if x]\n",
    "\n",
    "# maxI = len(split_into_sentences(body)) - 1\n",
    "\n",
    "# @interact\n",
    "# def test(i=widgets.IntSlider(min=0,max=maxI,step=1,value=0)):\n",
    "#     sentence = split_into_sentences(body)[i]\n",
    "#     pprint(sentence)\n",
    "#     pprint(tokenize(sentence))\n",
    "\n",
    "# folders = os.listdir(\"20news-bydate-test/\")\n",
    "\n",
    "\n",
    "# for folder in folders:\n",
    "#     files = os.listdir(f\"20news-bydate-test/{folder}/\")\n",
    "#     print(folder)\n",
    "    \n",
    "#     for file in files:\n",
    "# # folder = \"alt.atheism\"\n",
    "# # file = \"49960\"\n",
    "\n",
    "#         if not os.path.exists(f\"out/{folder}\"):\n",
    "#             os.makedirs(f\"out/{folder}\")\n",
    "#         out = open(f\"out/{folder}/{file}.tsv\", \"w\")\n",
    "#         mail = open(f\"20news-bydate-test/{folder}/{file}\", \"r\").read()\n",
    "#         head, body = split_mail(mail)\n",
    "\n",
    "#         for sentence in split_into_sentences(head):\n",
    "#             for token, stem, lem in tokenize(sentence):\n",
    "#                 out.write(f\"{token}\\t{stem}\\t{lem}\\n\")\n",
    "#             out.write(\"\\n\")\n",
    "\n",
    "#         for sentence in split_into_sentences(body):\n",
    "#             for token, stem, lem in tokenize(sentence):\n",
    "#                 out.write(f\"{token}\\t{stem}\\t{lem}\\n\")\n",
    "#             out.write(\"\\n\")\n",
    "\n",
    "#         out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Моя жалкая попытка 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyboardArray = [\n",
    "    ['`','1','2','3','4','5','6','7','8','9','0','-','='],\n",
    "    ['q','w','e','r','t','y','u','i','o','p','[',']','\\\\'],\n",
    "    ['a','s','d','f','g','h','j','k','l',';','\\''],\n",
    "    ['z','x','c','v','b','n','m',',','.','/'],\n",
    "    ['', '', ' ', ' ', ' ', ' ', ' ', '', '']\n",
    "    ]\n",
    "\n",
    "shiftedKeyboardArray = [\n",
    "    ['~', '!', '@', '#', '$', '%', '^', '&', '*', '(', ')', '+'],\n",
    "    ['Q', 'W', 'E', 'R', 'T', 'Y', 'U', 'I', 'O', 'P', '{', '}', '|'],\n",
    "    ['A', 'S', 'D', 'F', 'G', 'H', 'J', 'K', 'L', ':', '\"'],\n",
    "    ['Z', 'X', 'C', 'V', 'B', 'N', 'M', '<', '>', '?'],\n",
    "    ['', '', ' ', ' ', ' ', ' ', ' ', '', '']\n",
    "    ]\n",
    "\n",
    "def arrayForChar(c):\n",
    "    if (True in [c in r for r in keyboardArray]):\n",
    "        return keyboardArray\n",
    "    elif (True in [c in r for r in shiftedKeyboardArray]):\n",
    "        return shiftedKeyboardArray\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def getKeyboardXY(c, array):\n",
    "    if array == None:\n",
    "        return None\n",
    "    row = -1\n",
    "    column = -1\n",
    "    for r in array:\n",
    "        if c in r:\n",
    "            row = array.index(r)\n",
    "            column = r.index(c)\n",
    "            return (row, column)\n",
    "    return None\n",
    "\n",
    "def get_keyboard_distance(X, Y):\n",
    "    x = getKeyboardXY(X, arrayForChar(X))\n",
    "    y = getKeyboardXY(Y, arrayForChar(Y))\n",
    "    if x == None or y == None:\n",
    "        return 10\n",
    "    return ((x[0] - y[0])**2 + (x[1] - y[1])**2)**(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_removal_cost(X):\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_insertion_cost(X):\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_replacement_cost(X, Y):\n",
    "    return 1 #+ get_keyboard_distance(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_vagner_fisher(x, y):\n",
    "    len_x, len_y = len(x), len(y)\n",
    "    if len_x > len_y:\n",
    "        x, y = y, x\n",
    "        len_x, len_y = len_y, len_x\n",
    "\n",
    "    current_column = range(len_x + 1)\n",
    "    for i in range(1, len_y + 1):\n",
    "        previous_column = current_column\n",
    "        current_column = [i] + [0] * len_x\n",
    "\n",
    "        for j in range(1, len_x + 1):\n",
    "            insert = previous_column[j] + get_insertion_cost(y[i - 1])\n",
    "            remove = current_column[j - 1] + get_removal_cost(x[j - 1])\n",
    "            replace = previous_column[j - 1]\n",
    "        \n",
    "            if x[j - 1] != y[i - 1]:\n",
    "                replace += get_replacement_cost(x[j - 1], y[i - 1])\n",
    "            # if replace > 8:\n",
    "            #     return None\n",
    "            current_column[j] = min(insert, remove, replace)\n",
    "\n",
    "    return current_column[len_x]\n",
    "\n",
    "a = 'hypothesis'\n",
    "b = 'reference'\n",
    "\n",
    "start_time = datetime.now()\n",
    "dist = distance_vagner_fisher(a, b)\n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match(dictionary, word):\n",
    "    if(len(word) <= 3):\n",
    "        return 0, word\n",
    "    dist_min, word_min = 10000, ''\n",
    "    for item in dictionary:\n",
    "        dist = distance_vagner_fisher(item, word)\n",
    "        if dist is not None and dist < dist_min:\n",
    "            dist_min = dist\n",
    "            word_min = item\n",
    "\n",
    "        if dist == 0 : break\n",
    "    \n",
    "    if dist_min == 10000:\n",
    "        return None\n",
    "\n",
    "    return dist_min, word_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in os.listdir(\"test_data/\"):\n",
    "    files = os.listdir(f\"test_data/{folder}/\")\n",
    "    for file in files:\n",
    "        with open(f\"out/{file}\", \"w\") as fout:\n",
    "            with open(f'dicts/{folder}.tsv') as dict_file:\n",
    "                dictionary = csv.reader(dict_file, delimiter=\"\\t\")\n",
    "                dictionary = [x[0] for x in dictionary if len(x[0]) > 2]\n",
    "                dictionary.sort(key = lambda x:len(x))\n",
    "                content = open(f\"test_data/{folder}/{file}\", \"r\").read()\n",
    "                for sentence in split_into_sentences(content):\n",
    "                    for token, stem, lem in tokenize(sentence):\n",
    "                        matched =  match(dictionary, token)\n",
    "                        if matched is not None:\n",
    "                            print(f\"{token}\\t{matched[1]}\\t{matched[0]}\")\n",
    "                            fout.write(f\"{token}\\t{matched[1]}\\t{matched[0]}\\n\")\n",
    "                        else:\n",
    "                            print(f\"{token}\\t{token}\")\n",
    "                            fout.write(f\"{token}\\t{token}\\t0\\n\")\n",
    "                    fout.write(\"\\n\")\n",
    "            break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(\"out/\"):\n",
    "    tsv = open(f\"out/{file}\").readlines()\n",
    "    total = len(tsv)\n",
    "    non_replaced = 0\n",
    "    for row in tsv:\n",
    "        t = row.replace(\"\\n\", '').split('\\t')\n",
    "        if t[2] == '0':\n",
    "            non_replaced = non_replaced + 1\n",
    "    print(non_replaced/total)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "original = [[]]\n",
    "replaced = [[]]\n",
    "before_replaced = [[]]\n",
    "\n",
    "with open(\"out/53068\") as f_replaced:\n",
    "    with open(\"lab1_tokens/53068.tsv\") as f_original:\n",
    "        for a_origibal in f_original.readlines():\n",
    "            if a_origibal == \"\\n\":\n",
    "                original.append([])\n",
    "                continue\n",
    "            a_origibal = a_origibal.replace(\"\\n\", \"\").split('\\t')\n",
    "            original[-1].append(a_origibal[0].lower())\n",
    "        \n",
    "        for b_replaced in f_replaced.readlines():\n",
    "            if b_replaced == \"\\n\":\n",
    "                replaced.append([])\n",
    "                before_replaced.append([])\n",
    "                continue\n",
    "            b_replaced = b_replaced.replace(\"\\n\", \"\").split('\\t')\n",
    "            replaced[-1].append(b_replaced[1].lower())\n",
    "            before_replaced[-1].append(b_replaced[0].lower())\n",
    "        \n",
    "        # for word in original:\n",
    "        #     total = total + 1\n",
    "        #     if word in replaced:\n",
    "        #         r = r + 1\n",
    "\n",
    "# print(total)\n",
    "# print(r)\n",
    "# print(r/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "r = 0\n",
    "\n",
    "for sentence in original:\n",
    "    for replaced_sentence in replaced:\n",
    "        if len(sentence) == len(replaced_sentence):\n",
    "            for word in sentence:\n",
    "                total = total + 1\n",
    "                if word in replaced_sentence:\n",
    "                    r = r + 1\n",
    "print(total)\n",
    "print(r)\n",
    "print(r/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "r = 0\n",
    "\n",
    "for sentence in original:\n",
    "    for replaced_sentence in before_replaced:\n",
    "        if len(sentence) == len(replaced_sentence):\n",
    "            for word in sentence:\n",
    "                total = total + 1\n",
    "                if word in replaced_sentence:\n",
    "                    r = r + 1\n",
    "print(total)\n",
    "print(r)\n",
    "print(r/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaced"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "239a9fa0287fc0fb48e1b84671738ced5172aadbf780861bac62c840610302f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
