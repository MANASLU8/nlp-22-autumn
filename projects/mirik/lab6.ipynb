{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_document_train = pd.read_csv(\"assets/td_train.tsv\", index_col=0)\n",
    "term_document_test = pd.read_csv(\"assets/td_test.tsv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_words_per_topic(lda):\n",
    "    words = np.array(term_document_train.columns)\n",
    "    for key, topic in enumerate(lda.components_):\n",
    "        print(f\"Топ 10 слов для топика {key}:\")\n",
    "        print([words[index] for index in topic.argsort()[-10:]])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_documents_per_topic(lda, pred):\n",
    "    index_names = ['Topic' + str(i) for i in range(lda.n_components)]\n",
    "    column_names = term_document_test.index\n",
    "    df_topic_document = pd.DataFrame(np.transpose(pred), columns=column_names, index=index_names)\n",
    "    df_topic_document = pd.DataFrame(\n",
    "        df_topic_document.apply(lambda x: list(df_topic_document.columns[np.array(x).argsort()[::-1][:5]]),\n",
    "                                axis=1).to_list(), columns=['1', '2', '3', '4', '5'])\n",
    "    print(df_topic_document.to_string(), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexities = {}\n",
    "def calculate_LDA(n):\n",
    "    lda = LDA(n_components=n)\n",
    "    lda = lda.fit(term_document_train)\n",
    "    pred = lda.transform(term_document_test)\n",
    "    perplexity = lda.perplexity(term_document_test)\n",
    "    print(f\"Topic number: {lda.n_components}, perplexity: {perplexity}\")\n",
    "    perplexities[n] = round(perplexity, 2)\n",
    "\n",
    "    top_words_per_topic(lda)\n",
    "    top_documents_per_topic(lda, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_LDA(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_LDA(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_LDA(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_LDA(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_LDA(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_topics = list(perplexities.keys())\n",
    "perplexity = list(perplexities.values())\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.plot(n_topics, perplexity)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max = 0.0\n",
    "best_degree = 3\n",
    "for degree in range(1, 6):\n",
    "    model = np.poly1d(np.polyfit(n_topics, perplexity, degree))\n",
    "    r2 = r2_score(perplexity, model(n_topics))\n",
    "    if r2 > max:\n",
    "        max = r2\n",
    "        best_degree = degree\n",
    "print(best_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = np.poly1d(np.polyfit(n_topics, perplexity, best_degree))\n",
    "line = np.linspace(1, 42)\n",
    "plt.scatter(n_topics, perplexity)\n",
    "plt.plot(line, model(line))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {}\n",
    "for iter in [5, 10, 20]:\n",
    "    lda_model = LDA(n_components=20, max_iter=iter)\n",
    "    lda_model = lda_model.fit(term_document_train)\n",
    "    perplexity = lda_model.perplexity(term_document_test)\n",
    "    print(f\"N_components: {lda_model.n_components}, max_iter: {iter}, perplexity: {perplexity}\")\n",
    "    pred = lda_model.transform(term_document_test)\n",
    "    result[iter] = (round(perplexity, 2), pred, iter)\n",
    "result = sorted(result.values(), key=operator.itemgetter(0))\n",
    "print(f\"Best perplexity = {result[0][0]} ({result[0][2]} iter)\")\n",
    "best_pred = result[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"assets/test_topics.tsv\", 'w') as file:\n",
    "    rows = \"\"\n",
    "    for predict, filename in zip(best_pred, term_document_test.index):\n",
    "        string = \"\"\n",
    "        for pred in predict:\n",
    "            string += '\\t' + str(round(pred, 3))\n",
    "        rows += filename + '\\t' + string[1:] + '\\n'\n",
    "    file.write(rows)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ed4d525ca6dc0f22f8b2fd4dc2dd129f85a6a249447cff82d5014df90417f5a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
