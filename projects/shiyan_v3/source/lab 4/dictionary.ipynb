{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание словаря токенов с указанием их частот по сформированной в результате выполнения первой лабораторной работы аннотации обучающей выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import re\n",
    "import copy\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import nltk\n",
    "import re \n",
    "import os\n",
    "import glob\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "stops = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary=dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataProcess(rootDir):\n",
    "    for lists in os.listdir(rootDir):\n",
    "                    path = os.path.join(rootDir, lists)\n",
    "                    for filename in glob.glob(path+'\\\\*'):\n",
    "                        with open(os.path.join(os.getcwd(), filename), 'r') as file:    \n",
    "                            for line in file:\n",
    "                                if line != '\\n':\n",
    "                                    token = re.split(r'\\t', line)[0]\n",
    "                                    if not re.match('\\W|\\d',token) and token not in stops:\n",
    "                                        dictionary[token] = dictionary.get(token, 0) + 1\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataProcess('D:\\\\S\\\\NLP\\\\nlp-22-autumn\\\\projects\\\\shiyan_v3\\\\assets\\\\annotated-corpus\\\\train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in list(dictionary):\n",
    "    if dictionary[token] <= 5:\n",
    "        del dictionary[token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dict(path,t):\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(t, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dict('data\\\\dictionary.pkl',dictionary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
