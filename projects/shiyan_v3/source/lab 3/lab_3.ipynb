{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Формируем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re \n",
    "\n",
    "def get_file_tokens(path):\n",
    "    tokens = []\n",
    "    with open(path, \"r\") as f:\n",
    "        line = f.readline()\n",
    "        while line:\n",
    "            if line:\n",
    "                if line!='\\n':\n",
    "                    token = line.split('\\t')\n",
    "                    t=token[len(token)-1]\n",
    "                    tokens.append(t[:len(t)-1])\n",
    "            line = f.readline()\n",
    "    f.close()\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "def GetAllTokens(rootDir):\n",
    "    tokens=[]\n",
    "    for lists in os.listdir(rootDir):\n",
    "                    path = os.path.join(rootDir, lists)\n",
    "                    for filename in glob.glob(path+'\\\\*'):\n",
    "                       tokens = tokens + get_file_tokens(filename)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = GetAllTokens('D:\\\\S\\\\NLP\\\\nlp-22-autumn\\\\projects\\\\shiyan_v3\\\\assets\\\\annotated-corpus\\\\train\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas+=GetAllTokens('D:\\\\S\\\\NLP\\\\nlp-22-autumn\\\\projects\\\\shiyan_v3\\\\assets\\\\annotated-corpus\\\\test\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dict(path,t):\n",
    "    with open(path, \"w\") as f:\n",
    "        for i in t:\n",
    "            f.write(i)\n",
    "            f.write('\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dict(\"lemmas_p.txt\",lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаление знаков пунктуации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "lemm=[]\n",
    "for l in lemmas:\n",
    "    if not re.match('\\.|\\?|\\,|\\:|\\!|\\<|\\>|\\-|\\'|\\\"|\\:|\\(|\\)|\\;',l):\n",
    "        lemm.append(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приведение к нижнему регистру"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lem=[]\n",
    "for l in lemm:\n",
    "    lem.append(l.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаление стоп слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "lm=[]\n",
    "for l in lem:\n",
    "\tif l not in stop_words:\n",
    "\t\tlm.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dict(\"lemmas.txt\",lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Извлечение триграмм и подсчет их частот"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dict(path):\n",
    "    dictionary = []\n",
    "    with open(path, \"r\") as f:\n",
    "        while True:\n",
    "            line=f.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            dictionary.append(line.replace('\\n',''))\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=read_dict(\"lemmas.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threegrams = []\n",
    "for i in range(len(data) - 2):\n",
    "        threegrams.append((data[i], data[i+1], data[i+2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threegrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs_treegram= dict()\n",
    "for threegram in threegrams:\n",
    "    freqs_treegram[threegram] = freqs_treegram.get(threegram, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs_treegram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs= dict()\n",
    "for d in data:\n",
    "    freqs[d] = freqs.get(d, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм расчета меры ассоциации: лексемы, MI (вариант 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import pow\n",
    "import math\n",
    "\n",
    "def mi(threegram, freqs_treegram,freqs, N):\n",
    "    ngram = 3\n",
    "    return math.log((freqs_treegram[threegram]/(freqs[threegram[0]]*freqs[threegram[1]]*freqs[threegram[2]]))*pow(N, ngram - 1),2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_measures=dict()\n",
    "for threegram in threegrams:\n",
    "    mi_measures[threegram]=mi(threegram=threegram,freqs_treegram=freqs_treegram,freqs=freqs,N=len(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_measures_sort=dict(sorted(mi_measures.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "threegram_top=Counter(mi_measures).most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threegram_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"threegram_top.txt\", \"w\") as f:\n",
    "    for key in mi_measures_sort:\n",
    "        f.write(str(key))\n",
    "        f.write(str(mi_measures_sort[key]))\n",
    "        f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.collocations import *\n",
    "\n",
    "\n",
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "finder = TrigramCollocationFinder.from_words(data)\n",
    "\n",
    "for i in finder.score_ngrams(trigram_measures.pmi):\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "07bf0638b6f9a97e679c0f68f4d26207adc48a6db7abe23794ff5c2169363bfe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
